In the past decade, significant advancements have been made in object detection within natural images, but aerial images have posed unique challenges due to variations in scale and orientation caused by the bird's-eye view perspective. A notable hindrance to progress in object detection in aerial images (ODAI) has been the absence of extensive benchmark datasets. The authors of the dataset address this issue by introducing the Dataset of Object deTection in Aerial images (DOTA), a large-scale dataset comprising 1,793,658 object instances from 18 categories, annotated with oriented bounding boxes, derived from 11,268 aerial images. They complement this dataset with comprehensive baselines, covering 10 state-of-the-art algorithms across more than 70 configurations, evaluating both speed and accuracy. Additionally, they offer a code library for ODAI and a website for algorithm evaluation. Previous DOTA challenges have garnered participation from over 1300 teams worldwide, fostering advancements in object detection in aerial images.

In the realm of Earth vision, the ability to observe Earth's surface with aerial images at high resolutions, up to half a meter, has opened avenues for various applications, including urban management, precision agriculture, and disaster relief. Object detection in aerial images (ODAI) plays a crucial role in these applications, given its utility in localizing objects of interest, such as vehicles and ships, and predicting their categories. However, ODAI poses unique challenges, including arbitrary orientations, scale variations, non-uniform object densities, and large aspect ratios. Aerial images differ significantly from natural images, particularly in terms of the arbitrary orientation of objects, necessitating rotation-invariant feature representations, which many deep neural network models struggle to achieve. Moreover, horizontal bounding box (HBB) representations commonly used in object detection cannot precisely outline oriented objects, such as ships and large vehicles. Oriented bounding box (OBB) representations are more suitable for aerial images, allowing differentiation of densely packed instances and extraction of rotation-invariant features.

The absence of large-scale annotated aerial image datasets has been a limitation, with some existing datasets lacking real-world challenges. The DOTA dataset, with its OBB annotations, addresses this gap, offering a substantial resource for research in ODAI. Another challenge is the domain difference between conventional object detectors trained on natural images and the requirements of ODAI. Comprehensive baselines and ablative analyses are crucial for developing new algorithms. However, comparing algorithms can be challenging due to diverse hardware, software platforms, and settings. The authors tackle this by providing a code library and unified hardware and software platforms for algorithm evaluation, facilitating comparisons and guiding future research.

To create DOTA, a diverse collection of aerial images was gathered from various sensors and platforms, including Google Earth, Gaofen-2 (GF-2) Satellite, Jilin-1 (JL-1) Satellite, and airborne images. The images were obtained from worldwide areas of interest and maintained their original sizes, offering a real-world representation. DOTA includes 18 categories of objects of interest, selected based on their frequency and practical value in real-world applications. For instance, categories like "helicopter" were included to address moving objects in aerial images. Notably, the use of oriented bounding boxes (OBBs) to represent objects introduces variations in how objects are represented, depending on the order of the points. Careful selection of the first point is required to indicate the "head" of the object, which differs for categories with varying visual cues.

The authors employed a customized annotation tool and trained volunteers to annotate the dataset. Expert annotations were used for training volunteers, with checks in place to ensure annotation quality. Missing annotations, often due to tiny objects, have minimal impact on the dataset, while inaccuracies in bounding box annotations are inherent in object detection datasets. Future research could explore modeling inaccuracies in OBB annotations in DOTA, particularly addressing boundary ambiguity in objects.